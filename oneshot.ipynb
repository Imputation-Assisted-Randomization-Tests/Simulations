{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a96620bc",
      "metadata": {},
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1fafce2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn import linear_model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.impute import SimpleImputer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03931460",
      "metadata": {},
      "outputs": [],
      "source": [
        "#load data\n",
        "X = np.load(\"/Users/jiaweizhang/research/data/X.npy\")\n",
        "Y = np.load(\"/Users/jiaweizhang/research/data/Y.npy\")\n",
        "Z = np.load(\"/Users/jiaweizhang/research/data/Z.npy\")\n",
        "M = np.load(\"/Users/jiaweizhang/research/data/M.npy\")\n",
        "\n",
        "display(pd.DataFrame(X))\n",
        "display(pd.DataFrame(Y))\n",
        "display(pd.DataFrame(Z))\n",
        "display(pd.DataFrame(M))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab684f3a",
      "metadata": {},
      "source": [
        "# One shot framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "koc_huNCosmJ",
      "metadata": {
        "id": "koc_huNCosmJ"
      },
      "outputs": [],
      "source": [
        "def split_df(df):\n",
        "    # Set the proportion of data to be split\n",
        "    split_proportion = 0.5\n",
        "\n",
        "    # Set a random seed for reproducibility\n",
        "    random_seed = 42\n",
        "\n",
        "    # Get the indices for the split\n",
        "    indices = df.index.tolist()\n",
        "    num_rows = len(df)\n",
        "    split_index = int(num_rows * split_proportion)\n",
        "\n",
        "    # Shuffle the indices randomly\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    # Get the randomly selected rows for each split\n",
        "    split1_indices = indices[:split_index]\n",
        "    split2_indices = indices[split_index:]\n",
        "\n",
        "    # Split the original DataFrame into two separate DataFrames\n",
        "    df1 = df.loc[split1_indices]\n",
        "    df2 = df.loc[split2_indices]\n",
        "    \n",
        "    return df1,df2\n",
        "\n",
        "def getY(df_pred,df_missing):\n",
        "    # get the predicted Y values for the missing values\n",
        "    Y_pred = []\n",
        "    m,n = df_pred.shape\n",
        "\n",
        "    #return Y_pred\n",
        "    for i in range(m):\n",
        "        for j in range(n):\n",
        "            if pd.isna(df_missing[i][j]):\n",
        "                Y_pred.append(df_pred[i][j])\n",
        "    \n",
        "    return Y_pred\n",
        "\n",
        "def one_shot_test(Z, X, M, Y, G1, G2, T, L=10000):\n",
        "    \"\"\"\n",
        "    A one-shot framework for testing H_0.\n",
        "\n",
        "    Args:\n",
        "    Z: 2D array of observed treatment indicators\n",
        "    X: 2D array of observed covariates\n",
        "    M: 2D array of observed missing indicators\n",
        "    Y: 2D array of observed values for K outcomes\n",
        "    G1: a function that takes (Z, X, M, Y_k) as input and returns the imputed value for outcome k\n",
        "    G2: a function that takes (Z, X, M, Y_k) as input and returns the imputed value for outcome k\n",
        "    T: a function that takes (Z, Y_k) as input and returns the test statistic for outcome k\n",
        "    L: number of Monte Carlo simulations (default is 10000)\n",
        "\n",
        "    Returns:\n",
        "    p1: 1D array of exact p-values for testing Fisher's sharp null in part 1\n",
        "    p2: 1D array of exact p-values for testing Fisher's sharp null in part 2\n",
        "    \"\"\"\n",
        "    # create data a whole data frame\n",
        "    Y_masked = np.ma.masked_array(Y, mask=M)\n",
        "    Y_masked = Y_masked.filled(np.nan)\n",
        "    df = pd.DataFrame(np.concatenate((Z, X, Y_masked), axis=1))\n",
        "\n",
        "    # randomly split the data into two parts\n",
        "    df1, df2 = split_df(df)\n",
        "\n",
        "    # impute the missing values and calculate the observed test statistics in part 1\n",
        "    G1.fit(df1)\n",
        "    df1_imputed = G1.transform(df1)\n",
        "    Y1_impute = df1_imputed.iloc[:, 2:df1_imputed.shape[1]]\n",
        "    Y1_impute = Y1_impute.to_numpy()\n",
        "\n",
        "    # impute the missing values and calculate the observed test statistics in part 2\n",
        "    G2.fit(df2)\n",
        "    df2_imputed = G2.transform(df2)\n",
        "    Y2_impute = df2_imputed.iloc[:, 2:df2_imputed.shape[1]]\n",
        "    Y2_impute = Y2_impute.to_numpy()\n",
        "\n",
        "    # simulate data and calculate test statistics\n",
        "    t1_sim = np.zeros((L, len(Y)))\n",
        "    t2_sim = np.zeros((L, len(Y)))\n",
        "    for l in range(L):\n",
        "        # simulate treatment indicators in parts 1 and 2\n",
        "        Z1_sim = np.random.binomial(1, 0.5, df1.shape[0])\n",
        "        Z2_sim = np.random.binomial(1, 0.5, df2.shape[0])\n",
        "        \n",
        "        # impute missing values in part 1 using G2\n",
        "        Y1_sim = [G2(Z1_sim, X1, M1, Y1_k) for Y1_k in Y1]\n",
        "\n",
        "        # impute missing values in part 2 using G1\n",
        "        Y2_sim = [G1(Z2_sim, X2, M2, Y2_k) for Y2_k in Y2]\n",
        "\n",
        "        # calculate test statistics for part 1 and part 2\n",
        "        for k in range(len(Y)):\n",
        "            t1_sim[l,k] = T(Z1_sim, Y1_sim[k])\n",
        "            t2_sim[l,k] =\n",
        "                # calculate exact p-values for each outcome\n",
        "    p1 = np.mean(t1_sim >= t1_obs, axis=0)\n",
        "    p2 = np.mean(t2_sim >= t2_obs, axis=0)\n",
        "    \n",
        "    return p1, p2\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "7d3e2280498d4d0bf5a6eb89edfba29687bb04994b150b07177e7fe6510e612b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
